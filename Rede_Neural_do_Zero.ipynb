{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW4xkS33WGzdNsHn4MAYGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucassenderski/Portfolio-Project/blob/main/Rede_Neural_do_Zero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "9yZyAsGLzsBi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()#Definindo a conversão de imagem para tensor\n",
        "\n",
        "trainset= datasets.MNIST('./MNIST_data/',download=True, train=True, transform=transform)#Carrega a parte de treino dodataset\n",
        "trainloader= torch.utils.data.DataLoader(trainset,batch_size=64, shuffle=True) #Cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Load the validation part of the dataset\n",
        "valloader = torch.utils.data.DataLoader (valset, batch_size=64, shuffle =True) # Creates a buffer to take the data in parts"
      ],
      "metadata": {
        "id": "00Jd2cu1z0K0"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pIr-O69EKbIq",
        "outputId": "ea0ac017-de5e-40b7-e0e8-c4a7a381b981"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape)#para verificar as dimensoes do tensor de cada imagem\n",
        "print(etiquetas[0].shape)#para verificar as dimensoes do tensor de cada etiqueta\n",
        "\n",
        "torch.Size([1, 28, 28])\n",
        "torch.Size([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MverJnnYMX_o",
        "outputId": "acfe2785-c680-4ad2-da87-9a09e69eb411"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super (Modelo, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
        "\n",
        "    #para a camada de saida não e necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self,X):\n",
        "\n",
        "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "        X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda\n",
        "\n"
      ],
      "metadata": {
        "id": "Yw5QKpzXOHE6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a polítca de atualização dos pesos e da bias\n",
        "    inicio =time() # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "    EPOCHS = 10 # numero de epochs que o algoritmo rodará\n",
        "    modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range (EPOCHS):\n",
        "\n",
        "        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "\n",
        "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28 28 casas pa otimizador.zero grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
        "\n",
        "            perda_instantanea.backward() # back propagation a partir da perda\n",
        "            otimizador.step() # atualizando os pesos e a bias\n",
        "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
        "\n",
        "        else:\n",
        "\n",
        "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "        print(\"\\nTempo de treino (em minutos) =\",(time()-inicio)/60)"
      ],
      "metadata": {
        "id": "WhKZOdJDRtD0"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas= 0,0\n",
        "\n",
        "    for imagens, etiquetas in valloader:\n",
        "\n",
        "      for i in range(len(etiquetas)):\n",
        "\n",
        "        img = imagens[i].view(1, 784)\n",
        "\n",
        "        #desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
        "\n",
        "        ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
        "\n",
        "        probab =list(ps.cpu().numpy()[0])\n",
        "\n",
        "        etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
        "\n",
        "        etiqueta_certa = etiquetas.numpy()[i]\n",
        "\n",
        "        if(etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
        "\n",
        "          conta_corretas +=1\n",
        "\n",
        "        conta_todas +=1\n",
        "\n",
        "      print(\"Total de imagens testadas =\", conta_todas)\n",
        "      print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "Y3GscTz8UJVY"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6-La7DhWRHF",
        "outputId": "4e4c171a-d25d-4a6e-e5c4-76d552cd1c5c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ]
}